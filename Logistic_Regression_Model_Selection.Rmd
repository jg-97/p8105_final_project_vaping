---
title: "Logistic Regression: Model Selection"
author: "Daniela Quigee (dq2147)"
date: "12/3/2019"
output: html_document
---
To select for the best model that can predict whether the kid vaped or not based on self reported status that they are willing to share, we rewrite our model selection method as function that can be mapped top a modelr cv object by purrr to streamline the crossvalidation proscess.


```{r setup, include = FALSE}
library(tidyverse)
library(modelr)
library(glmnet)
###This package provide glm like interface for glmnet
library(glmnetUtils)
set.seed(8105)
```

# Model standarization priming for selection

```{r }
## function for stepAIC method
log_reg_auto = function(cv_df){
  cv_df %>%mutate(
###Automodel selection with AIC as criterial
         automodel  = map(train, ~glm(current_vaping ~., data = .x, family = binomial(),na.action = na.exclude)%>%MASS::stepAIC(trace = FALSE))
 ) }

###function for lasso selection method
lasso = function(df){
  lasso_temp = cv.glmnet(current_vaping ~., data = df, family = "binomial")
glmnet(current_vaping ~., data = df, family = "binomial",lambda = lasso_temp$lambda.min)
}
### formular for manual selection
manual_formular = current_vaping ~ sad_hopeless + attempted_suicide + safety_concerns_at_school + 
    threatened_at_school + physical_fighting + bullying_electronically + 
    carring_weapon

###find prediction accuracy
accy = function(model,data){
  Temp = predict(model, data, type = "response")%>%round()
1-mean(Temp-(as.numeric(pull(as.tibble(data),current_vaping))-1))
}
```

# cross_validation dataset preparation:

```{r include=FALSE}

load("./data/nyc_data.RData")

# Creating the dataset we will use to build the model
df = df_total %>% 
  ### Select only the vairbale candidates from the data set 
  select(
    # binary respone
    current_vaping,
    # possible predictor
    borough,
    year,
    age,
    sex,
    race7,
    sad_hopeless,
    attempted_suicide,
    injurious_suicide_attempt,
    considered_suicide,
    safety_concerns_at_school,
    threatened_at_school,
    physical_fighting,
    bullying_at_school,
    bullying_electronically,
  illegal_injected_drug_use,
    carring_weapon,
    sex_before_13,
    current_sexual_activity)


df15 = df %>% filter(year == 2015) %>% 
  ###Wanna do complete analysis
  drop_na()

df17 = df%>%filter(year == 2017) %>% 
  ###Wanna do complete analysis
  drop_na()

```

```{r  }
cv_df =
  ## Making the CV_df by modelr, for 5 folds and 10 times.
  crossv_mc(df15,n=10)
```

# Model validation/Selection
The cv_df will be feeds to all three models and then the accuracy of prediction of each on the test dataset will compute and graphically displayed.

```{r  CrossValidation}

cv_df = cv_df %>%
##stepAIC
  log_reg_auto() %>%
  ## Manual model
  mutate(manual_model = map(train, ~glm(manual_formular, data = .x, family = binomial,na.action = na.exclude)))%>%
  ## Lasso model
 mutate(lasso_model = map(train,~lasso(.x)))

###Prediction Accuracy computation
cv_df = cv_df %>%
  mutate(
        accuracy_automodel= map2_dbl(.x = automodel,.y = test, ~accy(data =.y,model =.x)),
        accuracy_manualmodel= map2_dbl(.x = manual_model,.y = test, ~accy(data =.y,model =.x)),
        accuracy_lasso= map2_dbl(.x = lasso_model,.y = test, ~accy(data =.y,model =.x))
        )


###Graph accuracy distribution
cv_df %>% select(starts_with("accuracy")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "Accuracy",
    names_prefix = "accuracy_") %>% 
  mutate(Models = recode(model,automodel = "StepAIC Model",manualmodel = "Manual Model", lasso = "Lasso Model")) %>%
  ggplot(aes(x = Models, y = Accuracy)) + geom_violin()
```



## Final model selection

```{r  }
## The model generated using the full data set is recreated
Final_model =
  ## tibble
  tibble(train = list(df15),
         test = list(df17)) %>%
  ##stepAIC
  log_reg_auto() %>%
  ## Manual model
  mutate(manualmodel = map(train, ~glm(manual_formular, data = .x, family = binomial,na.action = na.exclude))) %>%
  ## Lasso model
  mutate(lassomodel = map(train,~lasso(.x)))
```

It occurs that the accuracy of the models generated by stepAIC are the best among the three models, also with a slightly better consistancy.In terms of number of predictors, the stepAIC model have `r nrow(Final_model[[1,5]]%>%broom::tidy())-nrow(Final_model[[1,3]]%>%broom::tidy())` less predictors than the lasso one.Therefore the stepAIC model will be the model of our choosing. 

## Performance in predicting 2017 behavior of all three models.


```{r }
Final_model %>%
  mutate(
        accuracy_automodel= map2_dbl(.x = automodel,.y = test, ~accy(data =.y,model =.x)),
        accuracy_manualmodel= map2_dbl(.x = manualmodel,.y = test, ~accy(data =.y,model =.x)),
        accuracy_lasso= map2_dbl(.x = lassomodel,.y = test, ~accy(data =.y,model =.x))
        ) %>%
  select("Accuracy StepAIC Model"=accuracy_automodel, "Accuracy Manual Model" = accuracy_manualmodel, "Accuracy Lasso Model"= accuracy_lasso)%>%round(digits = 3) %>% knitr::kable(caption = "Prediction Accuray by Model on 2017 data")
```

Consequntaily, the model of our choosing also turns out to give the most accurate prediction of the the vaping status for kids in 2017. The parameters of each predictos and the P value associated with it are shown as follow:

```{r}
Final_model[[1,3]] %>% broom::tidy() %>% knitr::kable()

Final_model[[1,3]]$formula

Final_model
```






