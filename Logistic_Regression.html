<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Daniela Quigee (dq2147)" />

<meta name="date" content="2019-12-01" />

<title>Logistic Regression</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/journal.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 61px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h2 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h3 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h4 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h5 {
  padding-top: 66px;
  margin-top: -66px;
}
.section h6 {
  padding-top: 66px;
  margin-top: -66px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Home</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="Overview.html">Project Overview</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://dani-quigee-shiny.shinyapps.io/My_first_Shiny/#section-drug-use">Explore the Data</a>
</li>
<li>
  <a href="Analysis.html">Analysis</a>
</li>
<li>
  <a href="Report.html">Report</a>
</li>
<li>
  <a href="Screencast.html">
    <span class="fa fa-video fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/jg-97/p8105_final_project_vaping">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Logistic Regression</h1>
<h4 class="author">Daniela Quigee (dq2147)</h4>
<h4 class="date">12/01/2019</h4>

</div>


<pre class="r"><code># Loading the cleaned data
load(&quot;./data/nyc_data.RData&quot;)
fill_NA = function(vector){
    as.factor(coalesce(as.character(vector),&quot;unknown&quot;))
}
set.seed(8105)</code></pre>
<p>###Manual selection</p>
<div id="function-definition" class="section level2">
<h2>Function definition</h2>
<p>The following code chunck define the functions that is gonna be used to generate and mapped on the cv dataframe, i.e. it build up the component of the pipeline.</p>
<pre class="r"><code>###Function that do auto log reg

## function for cv
#crossv_mc(df,n)

## function for autologreg
log_reg_auto = function(cv_df,formular = manual_formular){
  cv_df %&gt;%mutate(
###Automodel selection with AIC as criterial
         automodel  = map(train, ~glm(current_vaping ~., data = .x, family = binomial(),na.action = na.exclude)%&gt;%MASS::stepAIC(trace = FALSE))
 ) }


###Do lasso stat learning
lasso = function(cv_df){
  lasso_temp = cv.glmnet(current_vaping ~., data = cv_df, family = &quot;binomial&quot;)
glmnet(current_vaping ~., data = cv_df, family = &quot;binomial&quot;,lambda = lasso_temp$lambda.min)
}

###find prediction accuracy
accy = function(model,data){
  Temp = predict(model, data, type = &quot;response&quot;)%&gt;%round()
1-mean(Temp-(as.numeric(pull(as.tibble(data),current_vaping))-1))
  }</code></pre>
</div>
<div id="data-input-selection" class="section level2">
<h2>data input selection:</h2>
<p>This part control the datas that was used to feed in the pipeline</p>
<pre class="r"><code># Extracting necessary variables
df = df_total%&gt;%
  select(
    # binary respone
    current_vaping,
    # possible predictor
    carring_weapon,
    sad_hopeless,
    attempted_suicide,
    injurious_suicide_attempt,
    safety_concerns_at_school,
    threatened_at_school,
    physical_fighting,
    bullying_at_school,
    bullying_electronically,
    sex,
    age,
    race7,
<<<<<<< HEAD:Logistic-Regression.html
    borough,
    illegal_injected_drug_use,
sex_before_13,
multiple_sex_partner,
sexual_contact_2
,year)


df1517 = df%&gt;%filter(year == 2015|year == 2017)%&gt;%na.omit()
df15 = df%&gt;%filter(year == 2017)%&gt;%na.omit()
df17 = df%&gt;%filter(year == 2015)%&gt;%na.omit()</code></pre>
<div id="actual-pipeline" class="section level3">
<h3>Actual pipeline</h3>
<p>The following part commbine all the component of the pipelines and feed the table.</p>
<pre class="r"><code>###Set the manual selected predictor and response for the manual model
manual_formular = current_vaping ~ sad_hopeless + attempted_suicide  + safety_concerns_at_school + threatened_at_school + physical_fighting + bullying_electronically + carring_weapon + year

### run the actual pipeline
regtb_1517=
  ## CV 
  crossv_mc(df1517,n=10)%&gt;%
  ##stepAIC
  log_reg_auto()%&gt;%
  ## Manual model
  mutate(manualmodel = map(train, ~glm(manual_formular, data = .x, family = binomial,na.action = na.exclude)))%&gt;%
  ## Lasso model
  mutate(lassomodel = map(train,~lasso(.x)))</code></pre>
<pre><code>## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame</code></pre>
<pre><code>## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame</code></pre>
<pre><code>## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame</code></pre>
<pre><code>## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame</code></pre>
<pre><code>## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame</code></pre>
<pre><code>## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame</code></pre>
<pre><code>## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame</code></pre>
<pre><code>## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame</code></pre>
<pre><code>## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame</code></pre>
<pre><code>## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame</code></pre>
<pre><code>## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame</code></pre>
<pre><code>## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame</code></pre>
<pre><code>## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame</code></pre>
<pre><code>## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame</code></pre>
<pre><code>## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame</code></pre>
<pre><code>## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame</code></pre>
<pre><code>## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame</code></pre>
<pre><code>## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame</code></pre>
<pre><code>## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame</code></pre>
<pre><code>## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame</code></pre>
<pre class="r"><code>###Prediction Accuracy computation
regtb_1517=regtb_1517%&gt;%
  mutate(
        accuracy_automodel= map2_dbl(.x = automodel,.y = test, ~accy(data =.y,model =.x)),
        accuracy_manualmodel= map2_dbl(.x = manualmodel,.y = test, ~accy(data =.y,model =.x)),
        accuracy_lasso= map2_dbl(.x = lassomodel,.y = test, ~accy(data =.y,model =.x))
        )</code></pre>
<pre><code>## Warning: `as.tibble()` is deprecated, use `as_tibble()` (but mind the new semantics).
## This warning is displayed once per session.</code></pre>
<pre><code>## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame

## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame

## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame

## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame

## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame

## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame

## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame

## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame

## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame

## Warning in (function (formula, data, weights = NULL, offset = NULL, subset
## = NULL, : input data was converted to data.frame</code></pre>
<pre class="r"><code>###Graph accuracy distribution
regtb_1517%&gt;%select(starts_with(&quot;accuracy&quot;)) %&gt;% 
  pivot_longer(
    everything(),
    names_to = &quot;model&quot;, 
    values_to = &quot;accuracy&quot;,
    names_prefix = &quot;accuracy_&quot;) %&gt;% 
  mutate(model = fct_inorder(model)) %&gt;% 
  ggplot(aes(x = model, y = accuracy)) + geom_violin()</code></pre>
<p><img src="Logistic-Regression_files/figure-html/implimentation-1.png" width="672" /></p>
<pre class="r"><code>###Finalize model retrived:

Final_1517=
  ## CV 
  tibble(train = list(df1517),
         test = list(df1517))%&gt;%
  ##stepAIC
  log_reg_auto()%&gt;%
  ## Manual model
  mutate(manualmodel = map(train, ~glm(manual_formular, data = .x, family = binomial,na.action = na.exclude)))%&gt;%
  ## Lasso model
  mutate(lassomodel = map(train,~lasso(.x)))

Final_1517%&gt;%
  mutate(
        accuracy_automodel= map2_dbl(.x = automodel,.y = test, ~accy(data =.y,model =.x)),
        accuracy_manualmodel= map2_dbl(.x = manualmodel,.y = test, ~accy(data =.y,model =.x)),
        accuracy_lasso= map2_dbl(.x = lassomodel,.y = test, ~accy(data =.y,model =.x))
        )</code></pre>
<pre><code>## # A tibble: 1 x 8
##   train test  automodel manualmodel lassomodel accuracy_automo…
##   &lt;lis&gt; &lt;lis&gt; &lt;list&gt;    &lt;list&gt;      &lt;list&gt;                &lt;dbl&gt;
## 1 &lt;tib… &lt;tib… &lt;glm&gt;     &lt;glm&gt;       &lt;glmnt.fr&gt;            0.876
## # … with 2 more variables: accuracy_manualmodel &lt;dbl&gt;,
## #   accuracy_lasso &lt;dbl&gt;</code></pre>
<pre class="r"><code>final_modle_formula = list(
Final_1517[[1,3]]$formula,
Final_1517[[1,4]]$formula,
Final_1517[[1,5]]$terms
)
final_modle_formula</code></pre>
<pre><code>## [[1]]
## current_vaping ~ carring_weapon + sad_hopeless + attempted_suicide + 
##     safety_concerns_at_school + physical_fighting + bullying_at_school + 
##     bullying_electronically + sex + race7 + illegal_injected_drug_use + 
##     sexual_contact_2
## &lt;environment: 0x7f87f9a0c768&gt;
## 
## [[2]]
## current_vaping ~ sad_hopeless + attempted_suicide + safety_concerns_at_school + 
##     threatened_at_school + physical_fighting + bullying_electronically + 
##     carring_weapon + year
## 
## [[3]]
## ~carring_weapon + sad_hopeless + attempted_suicide + injurious_suicide_attempt + 
##     safety_concerns_at_school + threatened_at_school + physical_fighting + 
##     bullying_at_school + bullying_electronically + sex + age + 
##     race7 + borough + illegal_injected_drug_use + sex_before_13 + 
##     multiple_sex_partner + sexual_contact_2 + year</code></pre>
<pre class="r"><code>  accy(Final_1517[[1,5]],Final_1517[[1,1]])</code></pre>
<pre><code>## [1] 0.8706405</code></pre>
<div id="section" class="section level116">
<p></p>
<p>The incoperated log reg pipeline ends here</p>
<p>#Note that we could do the same procedure with the imputed data and see whether the prediction accuracy has been imporved.</p>
<p>#Also note that we could add more potential covariates into the model and see whether the prediction accuracy has been imporved.</p>
<p>#Compare with the original model ``{r} fit_logistic = glm(current_vaping ~ sad_hopeless + attempted_suicide + safety_concerns_at_school + threatened_at_school + physical_fighting + bullying_electronically + carring_weapon, data = data_tr, family = binomial())</p>
<p>fit_logistics_predict = round(predict(fit_logistic, data_te, type = “response”)) CrossTable(x = as.numeric(unlist(y_te))-1,y = fit_logistics_predict, prop.r = F, prop.c = F, prop.chisq = F) mean(as.numeric(unlist(y_te))-1 ==fit_logistics_predict)</p>
<pre><code></code></pre>
</div>
</div>
</div>
=======
    borough)
# Fitting a logistic regression model
fit_logistic = glm(current_vaping ~ sad_hopeless + attempted_suicide  + safety_concerns_at_school + threatened_at_school + physical_fighting + bullying_electronically + carring_weapon  , data = df, family = binomial())
fit_logistic %&gt;% 
  broom::tidy() %&gt;% 
  mutate(OR = exp(estimate)) %&gt;%
  knitr::kable(digits = 3)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std.error</th>
<th align="right">statistic</th>
<th align="right">p.value</th>
<th align="right">OR</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">-1.192</td>
<td align="right">0.172</td>
<td align="right">-6.915</td>
<td align="right">0.000</td>
<td align="right">0.304</td>
</tr>
<tr class="even">
<td align="left">sad_hopelessNo</td>
<td align="right">0.278</td>
<td align="right">0.073</td>
<td align="right">3.823</td>
<td align="right">0.000</td>
<td align="right">1.321</td>
</tr>
<tr class="odd">
<td align="left">attempted_suicideNo</td>
<td align="right">0.526</td>
<td align="right">0.104</td>
<td align="right">5.036</td>
<td align="right">0.000</td>
<td align="right">1.692</td>
</tr>
<tr class="even">
<td align="left">safety_concerns_at_schoolNo</td>
<td align="right">0.287</td>
<td align="right">0.121</td>
<td align="right">2.369</td>
<td align="right">0.018</td>
<td align="right">1.333</td>
</tr>
<tr class="odd">
<td align="left">threatened_at_schoolNo</td>
<td align="right">0.296</td>
<td align="right">0.135</td>
<td align="right">2.193</td>
<td align="right">0.028</td>
<td align="right">1.345</td>
</tr>
<tr class="even">
<td align="left">physical_fightingNo</td>
<td align="right">0.773</td>
<td align="right">0.075</td>
<td align="right">10.347</td>
<td align="right">0.000</td>
<td align="right">2.165</td>
</tr>
<tr class="odd">
<td align="left">bullying_electronicallyNo</td>
<td align="right">0.302</td>
<td align="right">0.094</td>
<td align="right">3.228</td>
<td align="right">0.001</td>
<td align="right">1.353</td>
</tr>
<tr class="even">
<td align="left">carring_weaponNo</td>
<td align="right">0.983</td>
<td align="right">0.110</td>
<td align="right">8.920</td>
<td align="right">0.000</td>
<td align="right">2.672</td>
</tr>
</tbody>
</table>
<pre class="r"><code># What is the contribution of each predictor? see: https://uc-r.github.io/logistic_regression#multi
caret::varImp(fit_logistic)</code></pre>
<pre><code>##                               Overall
## sad_hopelessNo               3.822561
## attempted_suicideNo          5.036263
## safety_concerns_at_schoolNo  2.368532
## threatened_at_schoolNo       2.193178
## physical_fightingNo         10.347481
## bullying_electronicallyNo    3.227808
## carring_weaponNo             8.920078</code></pre>
<pre class="r"><code># Pseudo R^2: see https://uc-r.github.io/logistic_regression#multi (Pseudo R^2 about 0.40 considered good)
pR2(  glm(current_vaping ~ sad_hopeless + attempted_suicide  + safety_concerns_at_school + threatened_at_school + physical_fighting + bullying_electronically + carring_weapon  , data = df, family = binomial())  )[&quot;McFadden&quot;]</code></pre>
<pre><code>##  McFadden 
## 0.3345769</code></pre>
<pre class="r"><code># Cross-Validating the model
data_train &lt;- trainControl(method = &quot;cv&quot;, number = 5)
model_caret &lt;- train(
  current_vaping ~ sad_hopeless + attempted_suicide  + safety_concerns_at_school + threatened_at_school + physical_fighting + bullying_electronically + carring_weapon,
                   data = df,
                   trControl = data_train,
                   method = &#39;glm&#39;,
                   family = binomial(),
                   na.action = na.pass)</code></pre>
<pre><code>## Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info =
## trainInfo, : There were missing values in resampled performance measures.</code></pre>
<pre class="r"><code># Model predictions using 4 parts of the data for training 
model_caret</code></pre>
<pre><code>## Generalized Linear Model 
## 
## 10191 samples
##     7 predictor
##     2 classes: &#39;Yes&#39;, &#39;No&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 9596, 8271, 8273, 8271, 8272, 8272, ... 
## Resampling results:
## 
##   Accuracy   Kappa     
##   0.8471262  0.09581872</code></pre>
<pre class="r"><code>AIC(fit_logistic)</code></pre>
<pre><code>## [1] 5906.472</code></pre>
>>>>>>> 172ccea276d1a5737171c12a09e7fab4f69b27be:Logistic_Regression.html




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
